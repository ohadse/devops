input {
    file {
        # Note the change in the name of the log file, this is for the full unzipped archive
        path => "<path to elk-workshop>/logstash/pipelines/httpd/data/access.log"
        start_position => beginning
        codec => plain
        # Also note the change in the name of the sincedb file
        sincedb_path => "<path to elk-workshop>/logstash/pipelines/httpd/access.sincedb"
    }
}

filter {
    grok {
        match => {
            "message" => "%{COMBINEDAPACHELOG}"
        }
    }
    # Geo-IP with a reduced set of fields 
    geoip {
        source => "clientip"
        fields => ["city_name", "country_name", "location"]
    }
    # Converts the timestamp field from the COMBINEDAPACHELOG to the special @timestamp field
    # This changes the event time, allowing batch parsing instead of live parsing
    date {
        # The HTTP date format
        match => ["timestamp", "dd/MMM/YYYY:HH:mm:ss Z"]
        # Drop the string representation after parsing the date
        remove_field => ["timestamp"]
    }
    # Adds a checksum-based ID to the document
    checksum {
        algorithm => "sha256"
        keys => ["message"]
    }
    # Checksum unfortunately does not allow you to specify the output field
    # Therefore add a mutate, to move the field to a metadata field
    mutate {
        add_field => { "[@metadata][computed_id]" => "%{logstash_checksum}" }
        remove_field => ["logstash_checksum"]
    }
}

output {
    elasticsearch {
        hosts => ["localhost:9200"]
        # Daily indices
        index => "httpd-%{+YYYY.MM.dd}"
        document_id => "%{[@metadata][computed_id]}"
    }
}
